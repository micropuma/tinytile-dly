// -----// IR Dump Before TutorialApplyTilingSpec (tutorial-apply-tiling-spec) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map1 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map3 = affine_map<(d0, d1, d2, d3) -> ()>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
    %1 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%arg1, %arg0 : tensor<128x3x3x128xf32>, tensor<5x82x102x128xf32>) outs(%broadcasted : tensor<5x80x100x128xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %3 = arith.mulf %in, %in_0 : f32
      %4 = arith.addf %out, %3 : f32
      linalg.yield %4 : f32
    } -> tensor<5x80x100x128xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %2 = linalg.generic {indexing_maps = [#map3, #map4, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %3 = arith.maxnumf %in, %in_0 : f32
      linalg.yield %3 : f32
    } -> tensor<5x80x100x128xf32>
    return %2 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before TutorialTileAndFuse (tutorial-tile-and-fuse) ('func.func' operation: @conv) //----- //
#map = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map1 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map3 = affine_map<(d0, d1, d2, d3) -> ()>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
    %1 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%arg1, %arg0 : tensor<128x3x3x128xf32>, tensor<5x82x102x128xf32>) outs(%broadcasted : tensor<5x80x100x128xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %3 = arith.mulf %in, %in_0 : f32
      %4 = arith.addf %out, %3 : f32
      linalg.yield %4 : f32
    } -> tensor<5x80x100x128xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %2 = linalg.generic {indexing_maps = [#map3, #map4, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
    ^bb0(%in: f32, %in_0: f32, %out: f32):
      %3 = arith.maxnumf %in, %in_0 : f32
      linalg.yield %3 : f32
    } -> tensor<5x80x100x128xf32>
    return %2 : tensor<5x80x100x128xf32>
  }
}


Tiling operation: %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%arg1, %arg0 : tensor<128x3x3x128xf32>, tensor<5x82x102x128xf32>) outs(%broadcasted : tensor<5x80x100x128xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
^bb0(%in: f32, %in_0: f32, %out: f32):
  %3 = arith.mulf %in, %in_0 : f32
  %4 = arith.addf %out, %3 : f32
  linalg.yield %4 : f32
} -> tensor<5x80x100x128xf32>
Inserted: %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
Inserted: %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
Inserted: %extracted_slice_1 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Erased: linalg.yield %7 : f32
Erased: %15 = "arith.addf"(%arg17, %14) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %14 = "arith.mulf"(%arg15, %arg16) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %7 = "linalg.generic"(%arg1, %arg0, %arg11) <{indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>], operandSegmentSizes = array<i32: 2, 1>}> ({
}) {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} : (tensor<128x3x3x128xf32>, tensor<5x82x102x128xf32>, tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
Inserted: tensor.parallel_insert_slice %4 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
Replaced: %1 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%arg1, %arg0 : tensor<128x3x3x128xf32>, tensor<5x82x102x128xf32>) outs(%broadcasted : tensor<5x80x100x128xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
^bb0(%in: f32, %in_0: f32, %out: f32):
  %4 = arith.mulf %in, %in_0 : f32
  %5 = arith.addf %out, %4 : f32
  linalg.yield %5 : f32
} -> tensor<5x80x100x128xf32>
Erased: linalg.yield %5 : f32
Erased: %14 = "arith.addf"(%arg17, %13) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %13 = "arith.mulf"(%arg15, %arg16) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %2 = "linalg.generic"(%arg1, %arg0, %1) <{indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>], operandSegmentSizes = array<i32: 2, 1>}> ({
}) {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} : (tensor<128x3x3x128xf32>, tensor<5x82x102x128xf32>, tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
Current FuncOp is: func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %broadcasted) -> (tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%extracted_slice_1 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %4 = arith.mulf %in, %in_2 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %3 = arith.maxnumf %in, %in_0 : f32
    linalg.yield %3 : f32
  } -> tensor<5x80x100x128xf32>
  return %2 : tensor<5x80x100x128xf32>
}
Number of candidates for fusion: 4
Candidate for fusion: %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
Candidate for fusion: %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
Candidate for fusion: %extracted_slice_1 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Candidate for fusion: tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
candidate is: %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %broadcasted) -> (tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%extracted_slice_1 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %4 = arith.mulf %in, %in_2 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %3 = arith.maxnumf %in, %in_0 : f32
    linalg.yield %3 : f32
  } -> tensor<5x80x100x128xf32>
  return %2 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %broadcasted) -> (tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%extracted_slice_1 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_2: f32, %out: f32):
      %4 = arith.mulf %in, %in_2 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %3 = arith.maxnumf %in, %in_0 : f32
    linalg.yield %3 : f32
  } -> tensor<5x80x100x128xf32>
  return %2 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_1 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Inserted: %extracted_slice_2 = tensor.extract_slice %broadcasted_1[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Inserted: %extracted_slice_3 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
Inserted: %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Erased: %extracted_slice_2 = tensor.extract_slice %broadcasted_1[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Erased: linalg.yield %arg9 : f32
Erased: %8 = "linalg.broadcast"(%arg2, %arg11) <{dimensions = array<i64: 0, 1, 2>}> ({
}) : (tensor<128xf32>, tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0) -> (tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %4 = arith.mulf %in, %in_5 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %3 = arith.maxnumf %in, %in_0 : f32
    linalg.yield %3 : f32
  } -> tensor<5x80x100x128xf32>
  return %2 : tensor<5x80x100x128xf32>
}
Trying consumer fusionfunc.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0) -> (tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_5: f32, %out: f32):
      %4 = arith.mulf %in, %in_5 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  %cst = arith.constant 0.000000e+00 : f32
  %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
  ^bb0(%in: f32, %in_0: f32, %out: f32):
    %3 = arith.maxnumf %in, %in_0 : f32
    linalg.yield %3 : f32
  } -> tensor<5x80x100x128xf32>
  return %2 : tensor<5x80x100x128xf32>
}
candidate is: tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
Inserted: %inserted_slice = tensor.insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
Inserted: %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Inserted: %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
Inserted: %22 = "tensor.extract_slice"(%arg1, %arg26) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: 0, 0, 0, -9223372036854775808>, static_sizes = array<i64: 128, 3, 3, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<128x3x3x128xf32>, index) -> tensor<128x3x3x64xf32>
Inserted: %22 = "tensor.extract_slice"(%arg0, %arg23, %arg24, %arg25) <{operandSegmentSizes = array<i32: 1, 3, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, 0>, static_sizes = array<i64: 1, 3, 7, 128>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<5x82x102x128xf32>, index, index, index) -> tensor<1x3x7x128xf32>
Inserted: %22 = "tensor.extract_slice"(%arg2, %arg26) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, static_offsets = array<i64: -9223372036854775808>, static_sizes = array<i64: 64>, static_strides = array<i64: 1>}> : (tensor<128xf32>, index) -> tensor<64xf32>
Inserted: %22 = "tensor.extract_slice"(%arg27, %arg23, %arg24, %arg25, %arg26) <{operandSegmentSizes = array<i32: 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<5x80x100x128xf32>, index, index, index, index) -> tensor<1x1x5x64xf32>
Inserted: %22 = "tensor.extract_slice"(%arg25, %arg21, %arg22, %arg23, %arg24) <{operandSegmentSizes = array<i32: 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<5x80x100x128xf32>, index, index, index, index) -> tensor<1x1x5x64xf32>
Inserted: %20 = "tensor.insert_slice"(%19, %arg22, %arg18, %arg19, %arg20, %arg21) <{operandSegmentSizes = array<i32: 1, 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x5x64xf32>, tensor<5x80x100x128xf32>, index, index, index, index) -> tensor<5x80x100x128xf32>
Inserted: %19 = "tensor.extract_slice"(%17, %arg15, %arg16, %arg17, %arg18) <{operandSegmentSizes = array<i32: 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<5x80x100x128xf32>, index, index, index, index) -> tensor<1x1x5x64xf32>
Inserted: %19 = "tensor.extract_slice"(%arg3, %arg15, %arg16, %arg17, %arg18) <{operandSegmentSizes = array<i32: 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<5x80x100x128xf32>, index, index, index, index) -> tensor<1x1x5x64xf32>
Inserted: %18 = "tensor.extract_slice"(%arg12, %arg7, %arg8, %arg9, %arg10) <{operandSegmentSizes = array<i32: 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<5x80x100x128xf32>, index, index, index, index) -> tensor<1x1x5x64xf32>
Inserted: "tensor.parallel_insert_slice"(%19, %arg12, %arg7, %arg8, %arg9, %arg10) <{operandSegmentSizes = array<i32: 1, 1, 4, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x5x64xf32>, tensor<5x80x100x128xf32>, index, index, index, index) -> ()
Replaced: %4 = "scf.forall"(%0) <{operandSegmentSizes = array<i32: 0, 0, 0, 1>, staticLowerBound = array<i64: 0, 0, 0, 0>, staticStep = array<i64: 1, 1, 5, 64>, staticUpperBound = array<i64: 5, 80, 100, 128>}> ({
}) : (tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
Erased: %4 = "scf.forall"(%0) <{operandSegmentSizes = array<i32: 0, 0, 0, 1>, staticLowerBound = array<i64: 0, 0, 0, 0>, staticStep = array<i64: 1, 1, 5, 64>, staticUpperBound = array<i64: 5, 80, 100, 128>}> ({
}) : (tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
Erased: linalg.yield %6 : f32
Erased: %20 = "arith.maxnumf"(%arg16, %arg17) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %14 = "linalg.generic"(%2, %13, %arg3) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 2, 1>}> ({
}) : (f32, tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
Replaced: %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %1#0 : f32, tensor<5x80x100x128xf32>) outs(%arg3 : tensor<5x80x100x128xf32>) {
^bb0(%in: f32, %in_0: f32, %out: f32):
  %3 = arith.maxnumf %in, %in_0 : f32
  linalg.yield %3 : f32
} -> tensor<5x80x100x128xf32>
Erased: linalg.yield %3 : f32
Erased: %5 = "arith.maxnumf"(%arg4, %arg5) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %4 = "linalg.generic"(%2, %3#0, %arg3) <{indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>], operandSegmentSizes = array<i32: 2, 1>}> ({
}) : (f32, tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32>
After consumer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
Trying consumer fusionfunc.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
candidate is: %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
Trying consumer fusionfunc.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
candidate is: %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
Trying consumer fusionfunc.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %broadcasted = linalg.broadcast ins(%arg2 : tensor<128xf32>) outs(%0 : tensor<5x80x100x128xf32>) dimensions = [0, 1, 2] 
  %cst = arith.constant 0.000000e+00 : f32
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted_3 = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %extracted_slice_4 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted_3 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.mulf %in, %in_8 : f32
      %5 = arith.addf %out, %4 : f32
      linalg.yield %5 : f32
    } -> tensor<1x1x5x64xf32>
    %inserted_slice = tensor.insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    %extracted_slice_5 = tensor.extract_slice %inserted_slice[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_6 = tensor.extract_slice %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %extracted_slice_7 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_7 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_8: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_8 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
// -----// IR Dump After TutorialTileAndFuse (tutorial-tile-and-fuse) ('func.func' operation: @conv) //----- //
#map = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map1 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map3 = affine_map<(d0, d1, d2, d3) -> ()>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
      %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %4 = arith.mulf %in, %in_4 : f32
        %5 = arith.addf %out, %4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      %extracted_slice_3 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %3 = linalg.generic {indexing_maps = [#map3, #map4, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %4 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %4 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
        tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1#1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before TutorialTileAndFuse (tutorial-tile-and-fuse) ('func.func' operation: @conv) //----- //
#map = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map1 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map3 = affine_map<(d0, d1, d2, d3) -> ()>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
      %2 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %4 = arith.mulf %in, %in_4 : f32
        %5 = arith.addf %out, %4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      %extracted_slice_3 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %3 = linalg.generic {indexing_maps = [#map3, #map4, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %4 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %4 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
        tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1#1 : tensor<5x80x100x128xf32>
  }
}


Tiling operation: %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
^bb0(%in: f32, %in_4: f32, %out: f32):
  %4 = arith.mulf %in, %in_4 : f32
  %5 = arith.addf %out, %4 : f32
  linalg.yield %5 : f32
} -> tensor<1x1x5x64xf32>
Inserted: %25 = "tensor.extract_slice"(%3, %arg17, %arg13, %arg15) <{operandSegmentSizes = array<i32: 1, 3, 0, 0>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808, -9223372036854775808, 0>, static_sizes = array<i64: 1, 1, 1, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<128x3x3x64xf32>, index, index, index) -> tensor<1x1x1x64xf32>
Inserted: %26 = "tensor.extract_slice"(%4, %arg13, %arg15, %arg17) <{operandSegmentSizes = array<i32: 1, 3, 0, 0>, static_offsets = array<i64: 0, -9223372036854775808, -9223372036854775808, -9223372036854775808>, static_sizes = array<i64: 1, 1, 5, 1>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x3x7x128xf32>, index, index, index) -> tensor<1x1x5x1xf32>
Inserted: %27 = "tensor.extract_slice"(%arg18) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x5x64xf32>) -> tensor<1x1x5x64xf32>
Erased: "linalg.yield"(%32) : (f32) -> ()
Erased: %32 = "arith.addf"(%arg24, %31) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %31 = "arith.mulf"(%arg22, %arg23) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %24 = "linalg.generic"(%3, %4, %arg18) <{indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>], operandSegmentSizes = array<i32: 2, 1>}> ({
}) {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} : (tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>, tensor<1x1x5x64xf32>) -> tensor<1x1x5x64xf32>
Inserted: %28 = "tensor.insert_slice"(%27, %arg18) <{operandSegmentSizes = array<i32: 1, 1, 0, 0, 0>, static_offsets = array<i64: 0, 0, 0, 0>, static_sizes = array<i64: 1, 1, 5, 64>, static_strides = array<i64: 1, 1, 1, 1>}> : (tensor<1x1x5x64xf32>, tensor<1x1x5x64xf32>) -> tensor<1x1x5x64xf32>
Replaced: %2 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice, %extracted_slice_0 : tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>) outs(%broadcasted : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
^bb0(%in: f32, %in_9: f32, %out: f32):
  %5 = arith.mulf %in, %in_9 : f32
  %6 = arith.addf %out, %5 : f32
  linalg.yield %6 : f32
} -> tensor<1x1x5x64xf32>
Erased: linalg.yield %6 : f32
Erased: %32 = "arith.addf"(%arg24, %31) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %31 = "arith.mulf"(%arg22, %arg23) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
Erased: %8 = "linalg.generic"(%3, %4, %7) <{indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = [#linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<parallel>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>, #linalg.iterator_type<reduction>], operandSegmentSizes = array<i32: 2, 1>}> ({
}) {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} : (tensor<128x3x3x64xf32>, tensor<1x3x7x128xf32>, tensor<1x1x5x64xf32>) -> tensor<1x1x5x64xf32>
Current FuncOp is: func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %c0 = arith.constant 0 : index
    %c0_3 = arith.constant 0 : index
    %c0_4 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c3_5 = arith.constant 3 : index
    %c128 = arith.constant 128 : index
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
      %4 = scf.for %arg12 = %c0_3 to %c3_5 step %c1_6 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg14 = %c0_4 to %c128 step %c1_7 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
          %extracted_slice_9 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_10 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_11 = tensor.extract_slice %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<1x1x5x64xf32>
          %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_9, %extracted_slice_10 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%extracted_slice_11 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
          ^bb0(%in: f32, %in_12: f32, %out: f32):
            %7 = arith.mulf %in, %in_12 : f32
            %8 = arith.addf %out, %7 : f32
            linalg.yield %8 : f32
          } -> tensor<1x1x5x64xf32>
          %inserted_slice = tensor.insert_slice %6 into %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<1x1x5x64xf32>
          scf.yield %inserted_slice : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      scf.yield %4 : tensor<1x1x5x64xf32>
    }
    %extracted_slice_8 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_8 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_9: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_9 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
Number of candidates for fusion: 4
Candidate for fusion: %extracted_slice_9 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
Candidate for fusion: %extracted_slice_10 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
Candidate for fusion: %extracted_slice_11 = tensor.extract_slice %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<1x1x5x64xf32>
Candidate for fusion: %inserted_slice = tensor.insert_slice %6 into %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<1x1x5x64xf32>
candidate is: %extracted_slice_9 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
Inserted: %extracted_slice_9 = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
Inserted: %extracted_slice_10 = tensor.extract_slice %extracted_slice_9[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %c0 = arith.constant 0 : index
    %c0_3 = arith.constant 0 : index
    %c0_4 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c3_5 = arith.constant 3 : index
    %c128 = arith.constant 128 : index
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
      %4 = scf.for %arg12 = %c0_3 to %c3_5 step %c1_6 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg14 = %c0_4 to %c128 step %c1_7 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
          %extracted_slice_9 = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
          %extracted_slice_10 = tensor.extract_slice %extracted_slice_9[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_11 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_12 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_13 = tensor.extract_slice %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<1x1x5x64xf32>
          %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_11, %extracted_slice_12 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%extracted_slice_13 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
          ^bb0(%in: f32, %in_14: f32, %out: f32):
            %7 = arith.mulf %in, %in_14 : f32
            %8 = arith.addf %out, %7 : f32
            linalg.yield %8 : f32
          } -> tensor<1x1x5x64xf32>
          %inserted_slice = tensor.insert_slice %6 into %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<1x1x5x64xf32>
          scf.yield %inserted_slice : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      scf.yield %4 : tensor<1x1x5x64xf32>
    }
    %extracted_slice_8 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_8 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_9: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_9 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_12 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
Inserted: %extracted_slice_12 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
Inserted: %extracted_slice_13 = tensor.extract_slice %extracted_slice_12[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %c0 = arith.constant 0 : index
    %c0_3 = arith.constant 0 : index
    %c0_4 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c3_5 = arith.constant 3 : index
    %c128 = arith.constant 128 : index
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
      %4 = scf.for %arg12 = %c0_3 to %c3_5 step %c1_6 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg14 = %c0_4 to %c128 step %c1_7 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
          %extracted_slice_9 = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
          %extracted_slice_10 = tensor.extract_slice %extracted_slice_9[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_11 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_12 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
          %extracted_slice_13 = tensor.extract_slice %extracted_slice_12[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_14 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_15 = tensor.extract_slice %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<1x1x5x64xf32>
          %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_11, %extracted_slice_14 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%extracted_slice_15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
          ^bb0(%in: f32, %in_16: f32, %out: f32):
            %7 = arith.mulf %in, %in_16 : f32
            %8 = arith.addf %out, %7 : f32
            linalg.yield %8 : f32
          } -> tensor<1x1x5x64xf32>
          %inserted_slice = tensor.insert_slice %6 into %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<1x1x5x64xf32>
          scf.yield %inserted_slice : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      scf.yield %4 : tensor<1x1x5x64xf32>
    }
    %extracted_slice_8 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_8 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_9: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_9 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_9 = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %c0 = arith.constant 0 : index
    %c0_3 = arith.constant 0 : index
    %c0_4 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c3_5 = arith.constant 3 : index
    %c128 = arith.constant 128 : index
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
      %4 = scf.for %arg12 = %c0_3 to %c3_5 step %c1_6 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg14 = %c0_4 to %c128 step %c1_7 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
          %extracted_slice_9 = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
          %extracted_slice_10 = tensor.extract_slice %extracted_slice_9[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_11 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_12 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
          %extracted_slice_13 = tensor.extract_slice %extracted_slice_12[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_14 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_15 = tensor.extract_slice %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<1x1x5x64xf32>
          %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_11, %extracted_slice_14 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%extracted_slice_15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
          ^bb0(%in: f32, %in_16: f32, %out: f32):
            %7 = arith.mulf %in, %in_16 : f32
            %8 = arith.addf %out, %7 : f32
            linalg.yield %8 : f32
          } -> tensor<1x1x5x64xf32>
          %inserted_slice = tensor.insert_slice %6 into %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<1x1x5x64xf32>
          scf.yield %inserted_slice : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      scf.yield %4 : tensor<1x1x5x64xf32>
    }
    %extracted_slice_8 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_8 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_9: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_9 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
candidate is: %extracted_slice_12 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
After producer fusion func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.empty() : tensor<5x80x100x128xf32>
  %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
    %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
    %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
    %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
    %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
    %c0 = arith.constant 0 : index
    %c0_3 = arith.constant 0 : index
    %c0_4 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c3_5 = arith.constant 3 : index
    %c128 = arith.constant 128 : index
    %c1 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    %c1_7 = arith.constant 1 : index
    %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
      %4 = scf.for %arg12 = %c0_3 to %c3_5 step %c1_6 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg14 = %c0_4 to %c128 step %c1_7 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
          %extracted_slice_9 = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
          %extracted_slice_10 = tensor.extract_slice %extracted_slice_9[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_11 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
          %extracted_slice_12 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
          %extracted_slice_13 = tensor.extract_slice %extracted_slice_12[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_14 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
          %extracted_slice_15 = tensor.extract_slice %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<1x1x5x64xf32>
          %6 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>, affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_11, %extracted_slice_14 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%extracted_slice_15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
          ^bb0(%in: f32, %in_16: f32, %out: f32):
            %7 = arith.mulf %in, %in_16 : f32
            %8 = arith.addf %out, %7 : f32
            linalg.yield %8 : f32
          } -> tensor<1x1x5x64xf32>
          %inserted_slice = tensor.insert_slice %6 into %arg15[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<1x1x5x64xf32>
          scf.yield %inserted_slice : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      scf.yield %4 : tensor<1x1x5x64xf32>
    }
    %extracted_slice_8 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
    %3 = linalg.generic {indexing_maps = [affine_map<(d0, d1, d2, d3) -> ()>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>, affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_8 : tensor<1x1x5x64xf32>) {
    ^bb0(%in: f32, %in_9: f32, %out: f32):
      %4 = arith.maxnumf %in, %in_9 : f32
      linalg.yield %4 : f32
    } -> tensor<1x1x5x64xf32>
    scf.forall.in_parallel {
      tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
    }
  }
  return %1#1 : tensor<5x80x100x128xf32>
}
// -----// IR Dump After TutorialTileAndFuse (tutorial-tile-and-fuse) ('func.func' operation: @conv) //----- //
#map = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map1 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map3 = affine_map<(d0, d1, d2, d3) -> ()>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
      %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
        %4 = scf.for %arg12 = %c0 to %c3 step %c1 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
          %5 = scf.for %arg14 = %c0 to %c128 step %c1 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %6 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %7 = arith.mulf %in, %in_6 : f32
              %8 = arith.addf %out, %7 : f32
              linalg.yield %8 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %6 : tensor<1x1x5x64xf32>
          }
          scf.yield %5 : tensor<1x1x5x64xf32>
        }
        scf.yield %4 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %3 = linalg.generic {indexing_maps = [#map3, #map4, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %4 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %4 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
        tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1#1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before LinalgGeneralizeNamedOpsPass (linalg-generalize-named-ops) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map1 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map3 = affine_map<(d0, d1, d2, d3) -> ()>
#map4 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %broadcasted = linalg.broadcast ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) dimensions = [0, 1, 2] 
      %2 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %broadcasted) -> (tensor<1x1x5x64xf32>) {
        %4 = scf.for %arg12 = %c0 to %c3 step %c1 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
          %5 = scf.for %arg14 = %c0 to %c128 step %c1 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %6 = linalg.generic {indexing_maps = [#map, #map1, #map2], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %7 = arith.mulf %in, %in_6 : f32
              %8 = arith.addf %out, %7 : f32
              linalg.yield %8 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %6 : tensor<1x1x5x64xf32>
          }
          scf.yield %5 : tensor<1x1x5x64xf32>
        }
        scf.yield %4 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %3 = linalg.generic {indexing_maps = [#map3, #map4, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %2 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %4 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %4 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %2 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
        tensor.parallel_insert_slice %3 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1#1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After LinalgGeneralizeNamedOpsPass (linalg-generalize-named-ops) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map5 = affine_map<(d0, d1, d2, d3) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<1x1x5x64xf32>
      %3 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %2) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg12 = %c0 to %c3 step %c1 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
          %6 = scf.for %arg14 = %c0 to %c128 step %c1 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %7 = linalg.generic {indexing_maps = [#map2, #map3, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %8 = arith.mulf %in, %in_6 : f32
              %9 = arith.addf %out, %8 : f32
              linalg.yield %9 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %7 : tensor<1x1x5x64xf32>
          }
          scf.yield %6 : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %4 = linalg.generic {indexing_maps = [#map5, #map1, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %3 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %5 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
        tensor.parallel_insert_slice %4 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1#1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map5 = affine_map<(d0, d1, d2, d3) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1:2 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %0, %arg9 = %arg3) -> (tensor<5x80x100x128xf32>, tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<1x1x5x64xf32>
      %3 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %2) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg12 = %c0 to %c3 step %c1 iter_args(%arg13 = %arg11) -> (tensor<1x1x5x64xf32>) {
          %6 = scf.for %arg14 = %c0 to %c128 step %c1 iter_args(%arg15 = %arg13) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg14, %arg10, %arg12, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg10, %arg12, %arg14] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %7 = linalg.generic {indexing_maps = [#map2, #map3, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg15 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %8 = arith.mulf %in, %in_6 : f32
              %9 = arith.addf %out, %8 : f32
              linalg.yield %9 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %7 : tensor<1x1x5x64xf32>
          }
          scf.yield %6 : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %4 = linalg.generic {indexing_maps = [#map5, #map1, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %3 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %5 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %3 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
        tensor.parallel_insert_slice %4 into %arg9[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1#1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map5 = affine_map<(d0, d1, d2, d3) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<1x1x5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %6 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %7 = linalg.generic {indexing_maps = [#map2, #map3, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg14 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %8 = arith.mulf %in, %in_6 : f32
              %9 = arith.addf %out, %8 : f32
              linalg.yield %9 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %7 : tensor<1x1x5x64xf32>
          }
          scf.yield %6 : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %4 = linalg.generic {indexing_maps = [#map5, #map1, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %3 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %5 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %4 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map5 = affine_map<(d0, d1, d2, d3) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<1x1x5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %6 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %7 = linalg.generic {indexing_maps = [#map2, #map3, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg14 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %8 = arith.mulf %in, %in_6 : f32
              %9 = arith.addf %out, %8 : f32
              linalg.yield %9 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %7 : tensor<1x1x5x64xf32>
          }
          scf.yield %6 : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %4 = linalg.generic {indexing_maps = [#map5, #map1, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %3 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %5 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %4 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before LoopInvariantCodeMotion (loop-invariant-code-motion) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map5 = affine_map<(d0, d1, d2, d3) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<1x1x5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %6 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %7 = linalg.generic {indexing_maps = [#map2, #map3, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg14 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %8 = arith.mulf %in, %in_6 : f32
              %9 = arith.addf %out, %8 : f32
              linalg.yield %9 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %7 : tensor<1x1x5x64xf32>
          }
          scf.yield %6 : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %4 = linalg.generic {indexing_maps = [#map5, #map1, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %3 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %5 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %4 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before LinalgFoldUnitExtentDimsPass (linalg-fold-unit-extent-dims) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1, d2, d3) -> (d3)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d0, d1, d2, d3)>
#map2 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d6, d4, d5, d3)>
#map3 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1 + d4, d2 + d5, d6)>
#map4 = affine_map<(d0, d1, d2, d3, d4, d5, d6) -> (d0, d1, d2, d3)>
#map5 = affine_map<(d0, d1, d2, d3) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = tensor.empty() : tensor<5x80x100x128xf32>
    %1 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %2 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%extracted_slice_2 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<1x1x5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (tensor<1x1x5x64xf32>) {
        %5 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %6 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_4 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_5 = tensor.extract_slice %extracted_slice_0[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %7 = linalg.generic {indexing_maps = [#map2, #map3, #map4], iterator_types = ["parallel", "parallel", "parallel", "parallel", "reduction", "reduction", "reduction"]} ins(%extracted_slice_4, %extracted_slice_5 : tensor<1x1x1x64xf32>, tensor<1x1x5x1xf32>) outs(%arg14 : tensor<1x1x5x64xf32>) attrs =  {lowering_config = {parallel = [1, 1, 5, 64], reduction = [0, 0, 0, 0, 1, 1, 1]}} {
            ^bb0(%in: f32, %in_6: f32, %out: f32):
              %8 = arith.mulf %in, %in_6 : f32
              %9 = arith.addf %out, %8 : f32
              linalg.yield %9 : f32
            } -> tensor<1x1x5x64xf32>
            scf.yield %7 : tensor<1x1x5x64xf32>
          }
          scf.yield %6 : tensor<1x1x5x64xf32>
        }
        scf.yield %5 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %4 = linalg.generic {indexing_maps = [#map5, #map1, #map1], iterator_types = ["parallel", "parallel", "parallel", "parallel"]} ins(%cst, %3 : f32, tensor<1x1x5x64xf32>) outs(%extracted_slice_3 : tensor<1x1x5x64xf32>) {
      ^bb0(%in: f32, %in_4: f32, %out: f32):
        %5 = arith.maxnumf %in, %in_4 : f32
        linalg.yield %5 : f32
      } -> tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %4 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %1 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After LinalgFoldUnitExtentDimsPass (linalg-fold-unit-extent-dims) ('builtin.module' operation) //----- //
#map = affine_map<(d0, d1) -> (d1)>
#map1 = affine_map<(d0, d1) -> (d0, d1)>
#map2 = affine_map<(d0, d1) -> (d0)>
#map3 = affine_map<(d0, d1) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%2 : tensor<5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %3 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %4 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %6 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %7 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_6 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_7 = tensor.extract_slice %extracted_slice_0[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_6[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_10 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %8 = tensor.empty() : tensor<5x64xf32>
            %extracted_slice_11 = tensor.extract_slice %extracted_slice_9[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %9 = linalg.generic {indexing_maps = [#map, #map2, #map1, #map1], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_8, %extracted_slice_11, %extracted_slice_10 : tensor<64xf32>, tensor<5xf32>, tensor<5x64xf32>) outs(%8 : tensor<5x64xf32>) {
            ^bb0(%in: f32, %in_13: f32, %in_14: f32, %out: f32):
              %10 = arith.mulf %in, %in_13 : f32
              %11 = arith.addf %in_14, %10 : f32
              linalg.yield %11 : f32
            } -> tensor<5x64xf32>
            %inserted_slice_12 = tensor.insert_slice %9 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_12 : tensor<1x1x5x64xf32>
          }
          scf.yield %7 : tensor<1x1x5x64xf32>
        }
        scf.yield %6 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_3 = tensor.extract_slice %4[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %extracted_slice_2[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %5 = linalg.generic {indexing_maps = [#map3, #map1, #map1], iterator_types = ["parallel", "parallel"]} ins(%cst, %extracted_slice_3 : f32, tensor<5x64xf32>) outs(%extracted_slice_4 : tensor<5x64xf32>) {
      ^bb0(%in: f32, %in_6: f32, %out: f32):
        %6 = arith.maxnumf %in, %in_6 : f32
        linalg.yield %6 : f32
      } -> tensor<5x64xf32>
      %inserted_slice_5 = tensor.insert_slice %5 into %extracted_slice_2[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_5 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before TutorialVectorization (tutorial-vectorization) ('func.func' operation: @conv) //----- //
#map = affine_map<(d0, d1) -> (d1)>
#map1 = affine_map<(d0, d1) -> (d0, d1)>
#map2 = affine_map<(d0, d1) -> (d0)>
#map3 = affine_map<(d0, d1) -> ()>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_0 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_1 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = linalg.generic {indexing_maps = [#map, #map1], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_1 : tensor<64xf32>) outs(%2 : tensor<5x64xf32>) {
      ^bb0(%in: f32, %out: f32):
        linalg.yield %in : f32
      } -> tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %3 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %4 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %6 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %7 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_6 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_7 = tensor.extract_slice %extracted_slice_0[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_6[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_10 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %8 = tensor.empty() : tensor<5x64xf32>
            %extracted_slice_11 = tensor.extract_slice %extracted_slice_9[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %9 = linalg.generic {indexing_maps = [#map, #map2, #map1, #map1], iterator_types = ["parallel", "parallel"]} ins(%extracted_slice_8, %extracted_slice_11, %extracted_slice_10 : tensor<64xf32>, tensor<5xf32>, tensor<5x64xf32>) outs(%8 : tensor<5x64xf32>) {
            ^bb0(%in: f32, %in_13: f32, %in_14: f32, %out: f32):
              %10 = arith.mulf %in, %in_13 : f32
              %11 = arith.addf %in_14, %10 : f32
              linalg.yield %11 : f32
            } -> tensor<5x64xf32>
            %inserted_slice_12 = tensor.insert_slice %9 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_12 : tensor<1x1x5x64xf32>
          }
          scf.yield %7 : tensor<1x1x5x64xf32>
        }
        scf.yield %6 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_2 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_3 = tensor.extract_slice %4[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %extracted_slice_2[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %5 = linalg.generic {indexing_maps = [#map3, #map1, #map1], iterator_types = ["parallel", "parallel"]} ins(%cst, %extracted_slice_3 : f32, tensor<5x64xf32>) outs(%extracted_slice_4 : tensor<5x64xf32>) {
      ^bb0(%in: f32, %in_6: f32, %out: f32):
        %6 = arith.maxnumf %in, %in_6 : f32
        linalg.yield %6 : f32
      } -> tensor<5x64xf32>
      %inserted_slice_5 = tensor.insert_slice %5 into %extracted_slice_2[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_5 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After TutorialVectorization (tutorial-vectorization) ('func.func' operation: @conv) //----- //
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_1 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_2 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = vector.transfer_read %extracted_slice_2[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
      %4 = vector.broadcast %3 : vector<64xf32> to vector<5x64xf32>
      %5 = vector.transfer_write %4, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %5 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %6 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %10 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %11 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_7 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_1[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_10 = tensor.extract_slice %extracted_slice_8[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_11 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %12 = tensor.empty() : tensor<5x64xf32>
            %extracted_slice_12 = tensor.extract_slice %extracted_slice_10[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %13 = vector.transfer_read %extracted_slice_9[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
            %14 = vector.broadcast %13 : vector<64xf32> to vector<5x64xf32>
            %15 = vector.transfer_read %extracted_slice_12[%c0], %cst_0 {in_bounds = [true]} : tensor<5xf32>, vector<5xf32>
            %16 = vector.broadcast %15 : vector<5xf32> to vector<64x5xf32>
            %17 = vector.transpose %16, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %18 = vector.transfer_read %extracted_slice_11[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
            %19 = arith.mulf %14, %17 : vector<5x64xf32>
            %20 = arith.addf %18, %19 : vector<5x64xf32>
            %21 = vector.transfer_write %20, %12[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
            %inserted_slice_13 = tensor.insert_slice %21 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_13 : tensor<1x1x5x64xf32>
          }
          scf.yield %11 : tensor<1x1x5x64xf32>
        }
        scf.yield %10 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %6[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_5 = tensor.extract_slice %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %7 = vector.transfer_read %extracted_slice_4[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
      %8 = arith.maxnumf %7, %cst : vector<5x64xf32>
      %9 = vector.transfer_write %8, %extracted_slice_5[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice_6 = tensor.insert_slice %9 into %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_6 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_1 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_2 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = vector.transfer_read %extracted_slice_2[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
      %4 = vector.broadcast %3 : vector<64xf32> to vector<5x64xf32>
      %5 = vector.transfer_write %4, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %5 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %6 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %10 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %11 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_7 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_1[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_10 = tensor.extract_slice %extracted_slice_8[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_11 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %12 = tensor.empty() : tensor<5x64xf32>
            %extracted_slice_12 = tensor.extract_slice %extracted_slice_10[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %13 = vector.transfer_read %extracted_slice_9[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
            %14 = vector.broadcast %13 : vector<64xf32> to vector<5x64xf32>
            %15 = vector.transfer_read %extracted_slice_12[%c0], %cst_0 {in_bounds = [true]} : tensor<5xf32>, vector<5xf32>
            %16 = vector.broadcast %15 : vector<5xf32> to vector<64x5xf32>
            %17 = vector.transpose %16, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %18 = vector.transfer_read %extracted_slice_11[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
            %19 = arith.mulf %14, %17 : vector<5x64xf32>
            %20 = arith.addf %18, %19 : vector<5x64xf32>
            %21 = vector.transfer_write %20, %12[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
            %inserted_slice_13 = tensor.insert_slice %21 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_13 : tensor<1x1x5x64xf32>
          }
          scf.yield %11 : tensor<1x1x5x64xf32>
        }
        scf.yield %10 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %6[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_5 = tensor.extract_slice %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %7 = vector.transfer_read %extracted_slice_4[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
      %8 = arith.maxnumf %7, %cst : vector<5x64xf32>
      %9 = vector.transfer_write %8, %extracted_slice_5[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice_6 = tensor.insert_slice %9 into %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_6 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_1 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_2 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = vector.transfer_read %extracted_slice_2[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
      %4 = vector.broadcast %3 : vector<64xf32> to vector<5x64xf32>
      %5 = vector.transfer_write %4, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %5 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %6 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %10 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %11 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_7 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_1[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_10 = tensor.extract_slice %extracted_slice_8[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_11 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %12 = tensor.empty() : tensor<5x64xf32>
            %extracted_slice_12 = tensor.extract_slice %extracted_slice_10[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %13 = vector.transfer_read %extracted_slice_9[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
            %14 = vector.broadcast %13 : vector<64xf32> to vector<5x64xf32>
            %15 = vector.transfer_read %extracted_slice_12[%c0], %cst_0 {in_bounds = [true]} : tensor<5xf32>, vector<5xf32>
            %16 = vector.broadcast %15 : vector<5xf32> to vector<64x5xf32>
            %17 = vector.transpose %16, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %18 = vector.transfer_read %extracted_slice_11[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
            %19 = arith.mulf %14, %17 : vector<5x64xf32>
            %20 = arith.addf %18, %19 : vector<5x64xf32>
            %21 = vector.transfer_write %20, %12[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
            %inserted_slice_13 = tensor.insert_slice %21 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_13 : tensor<1x1x5x64xf32>
          }
          scf.yield %11 : tensor<1x1x5x64xf32>
        }
        scf.yield %10 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %6[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_5 = tensor.extract_slice %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %7 = vector.transfer_read %extracted_slice_4[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
      %8 = arith.maxnumf %7, %cst : vector<5x64xf32>
      %9 = vector.transfer_write %8, %extracted_slice_5[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice_6 = tensor.insert_slice %9 into %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_6 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After CSE (cse) ('builtin.module' operation) //----- //
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_1 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_2 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = vector.transfer_read %extracted_slice_2[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
      %4 = vector.broadcast %3 : vector<64xf32> to vector<5x64xf32>
      %5 = vector.transfer_write %4, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %5 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %6 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %10 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %11 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_7 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_1[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_10 = tensor.extract_slice %extracted_slice_8[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_11 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %extracted_slice_12 = tensor.extract_slice %extracted_slice_10[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %12 = vector.transfer_read %extracted_slice_9[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
            %13 = vector.broadcast %12 : vector<64xf32> to vector<5x64xf32>
            %14 = vector.transfer_read %extracted_slice_12[%c0], %cst_0 {in_bounds = [true]} : tensor<5xf32>, vector<5xf32>
            %15 = vector.broadcast %14 : vector<5xf32> to vector<64x5xf32>
            %16 = vector.transpose %15, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %17 = vector.transfer_read %extracted_slice_11[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
            %18 = arith.mulf %13, %16 : vector<5x64xf32>
            %19 = arith.addf %17, %18 : vector<5x64xf32>
            %20 = vector.transfer_write %19, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
            %inserted_slice_13 = tensor.insert_slice %20 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_13 : tensor<1x1x5x64xf32>
          }
          scf.yield %11 : tensor<1x1x5x64xf32>
        }
        scf.yield %10 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %6[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_5 = tensor.extract_slice %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %7 = vector.transfer_read %extracted_slice_4[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
      %8 = arith.maxnumf %7, %cst : vector<5x64xf32>
      %9 = vector.transfer_write %8, %extracted_slice_5[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice_6 = tensor.insert_slice %9 into %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_6 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before FoldTensorSubsetOps (fold-tensor-subset-ops) ('builtin.module' operation) //----- //
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %extracted_slice = tensor.extract_slice %arg1[0, 0, 0, %arg7] [128, 3, 3, 64] [1, 1, 1, 1] : tensor<128x3x3x128xf32> to tensor<128x3x3x64xf32>
      %extracted_slice_1 = tensor.extract_slice %arg0[%arg4, %arg5, %arg6, 0] [1, 3, 7, 128] [1, 1, 1, 1] : tensor<5x82x102x128xf32> to tensor<1x3x7x128xf32>
      %extracted_slice_2 = tensor.extract_slice %arg2[%arg7] [64] [1] : tensor<128xf32> to tensor<64xf32>
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = tensor.empty() : tensor<5x64xf32>
      %3 = vector.transfer_read %extracted_slice_2[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
      %4 = vector.broadcast %3 : vector<64xf32> to vector<5x64xf32>
      %5 = vector.transfer_write %4, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice = tensor.insert_slice %5 into %1[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      %6 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %inserted_slice) -> (tensor<1x1x5x64xf32>) {
        %10 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %11 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %extracted_slice_7 = tensor.extract_slice %extracted_slice[%arg13, %arg9, %arg11, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<128x3x3x64xf32> to tensor<1x1x1x64xf32>
            %extracted_slice_8 = tensor.extract_slice %extracted_slice_1[0, %arg9, %arg11, %arg13] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x3x7x128xf32> to tensor<1x1x5x1xf32>
            %extracted_slice_9 = tensor.extract_slice %extracted_slice_7[0, 0, 0, 0] [1, 1, 1, 64] [1, 1, 1, 1] : tensor<1x1x1x64xf32> to tensor<64xf32>
            %extracted_slice_10 = tensor.extract_slice %extracted_slice_8[0, 0, 0, 0] [1, 1, 5, 1] [1, 1, 1, 1] : tensor<1x1x5x1xf32> to tensor<1x5xf32>
            %extracted_slice_11 = tensor.extract_slice %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
            %extracted_slice_12 = tensor.extract_slice %extracted_slice_10[0, 0] [1, 5] [1, 1] : tensor<1x5xf32> to tensor<5xf32>
            %12 = vector.transfer_read %extracted_slice_9[%c0], %cst_0 {in_bounds = [true]} : tensor<64xf32>, vector<64xf32>
            %13 = vector.broadcast %12 : vector<64xf32> to vector<5x64xf32>
            %14 = vector.transfer_read %extracted_slice_12[%c0], %cst_0 {in_bounds = [true]} : tensor<5xf32>, vector<5xf32>
            %15 = vector.broadcast %14 : vector<5xf32> to vector<64x5xf32>
            %16 = vector.transpose %15, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %17 = vector.transfer_read %extracted_slice_11[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
            %18 = arith.mulf %13, %16 : vector<5x64xf32>
            %19 = arith.addf %17, %18 : vector<5x64xf32>
            %20 = vector.transfer_write %19, %2[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
            %inserted_slice_13 = tensor.insert_slice %20 into %arg14[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
            scf.yield %inserted_slice_13 : tensor<1x1x5x64xf32>
          }
          scf.yield %11 : tensor<1x1x5x64xf32>
        }
        scf.yield %10 : tensor<1x1x5x64xf32>
      }
      %extracted_slice_3 = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_4 = tensor.extract_slice %6[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %extracted_slice_5 = tensor.extract_slice %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %7 = vector.transfer_read %extracted_slice_4[%c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<5x64xf32>, vector<5x64xf32>
      %8 = arith.maxnumf %7, %cst : vector<5x64xf32>
      %9 = vector.transfer_write %8, %extracted_slice_5[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      %inserted_slice_6 = tensor.insert_slice %9 into %extracted_slice_3[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<1x1x5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %inserted_slice_6 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After FoldTensorSubsetOps (fold-tensor-subset-ops) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %3 = vector.broadcast %2 : vector<64xf32> to vector<5x64xf32>
      %4 = vector.transfer_write %3, %1[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
      %5 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %4) -> (tensor<1x1x5x64xf32>) {
        %9 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %10 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %11 = vector.transfer_read %arg1[%arg13, %arg9, %arg11, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %12 = vector.broadcast %11 : vector<64xf32> to vector<5x64xf32>
            %13 = affine.apply #map()[%arg5, %arg9]
            %14 = affine.apply #map()[%arg6, %arg11]
            %15 = vector.transfer_read %arg0[%arg4, %13, %14, %arg13], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %16 = vector.broadcast %15 : vector<5xf32> to vector<64x5xf32>
            %17 = vector.transpose %16, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %18 = vector.transfer_read %arg14[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
            %19 = arith.mulf %12, %17 : vector<5x64xf32>
            %20 = arith.addf %18, %19 : vector<5x64xf32>
            %21 = vector.transfer_write %20, %arg14[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
            scf.yield %21 : tensor<1x1x5x64xf32>
          }
          scf.yield %10 : tensor<1x1x5x64xf32>
        }
        scf.yield %9 : tensor<1x1x5x64xf32>
      }
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %6 = vector.transfer_read %5[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
      %7 = arith.maxnumf %6, %cst : vector<5x64xf32>
      %8 = vector.transfer_write %7, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %8 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before LoopInvariantSubsetHoisting (loop-invariant-subset-hoisting) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %3 = vector.broadcast %2 : vector<64xf32> to vector<5x64xf32>
      %4 = vector.transfer_write %3, %1[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
      %5 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %4) -> (tensor<1x1x5x64xf32>) {
        %9 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (tensor<1x1x5x64xf32>) {
          %10 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (tensor<1x1x5x64xf32>) {
            %11 = vector.transfer_read %arg1[%arg13, %arg9, %arg11, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %12 = vector.broadcast %11 : vector<64xf32> to vector<5x64xf32>
            %13 = affine.apply #map()[%arg5, %arg9]
            %14 = affine.apply #map()[%arg6, %arg11]
            %15 = vector.transfer_read %arg0[%arg4, %13, %14, %arg13], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %16 = vector.broadcast %15 : vector<5xf32> to vector<64x5xf32>
            %17 = vector.transpose %16, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %18 = vector.transfer_read %arg14[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
            %19 = arith.mulf %12, %17 : vector<5x64xf32>
            %20 = arith.addf %18, %19 : vector<5x64xf32>
            %21 = vector.transfer_write %20, %arg14[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
            scf.yield %21 : tensor<1x1x5x64xf32>
          }
          scf.yield %10 : tensor<1x1x5x64xf32>
        }
        scf.yield %9 : tensor<1x1x5x64xf32>
      }
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %6 = vector.transfer_read %5[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
      %7 = arith.maxnumf %6, %cst : vector<5x64xf32>
      %8 = vector.transfer_write %7, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %8 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After LoopInvariantSubsetHoisting (loop-invariant-subset-hoisting) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %3 = vector.broadcast %2 : vector<64xf32> to vector<5x64xf32>
      %4 = vector.transfer_write %3, %1[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
      %5 = vector.transfer_read %4[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
      %6:2 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %4, %arg11 = %5) -> (tensor<1x1x5x64xf32>, vector<5x64xf32>) {
        %11:2 = scf.for %arg12 = %c0 to %c3 step %c1 iter_args(%arg13 = %arg10, %arg14 = %arg11) -> (tensor<1x1x5x64xf32>, vector<5x64xf32>) {
          %12:2 = scf.for %arg15 = %c0 to %c128 step %c1 iter_args(%arg16 = %arg13, %arg17 = %arg14) -> (tensor<1x1x5x64xf32>, vector<5x64xf32>) {
            %13 = vector.transfer_read %arg1[%arg15, %arg9, %arg12, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %14 = vector.broadcast %13 : vector<64xf32> to vector<5x64xf32>
            %15 = affine.apply #map()[%arg5, %arg9]
            %16 = affine.apply #map()[%arg6, %arg12]
            %17 = vector.transfer_read %arg0[%arg4, %15, %16, %arg15], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %18 = vector.broadcast %17 : vector<5xf32> to vector<64x5xf32>
            %19 = vector.transpose %18, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %20 = arith.mulf %14, %19 : vector<5x64xf32>
            %21 = arith.addf %arg17, %20 : vector<5x64xf32>
            scf.yield %arg16, %21 : tensor<1x1x5x64xf32>, vector<5x64xf32>
          }
          scf.yield %12#0, %12#1 : tensor<1x1x5x64xf32>, vector<5x64xf32>
        }
        scf.yield %11#0, %11#1 : tensor<1x1x5x64xf32>, vector<5x64xf32>
      }
      %7 = vector.transfer_write %6#1, %6#0[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %8 = vector.transfer_read %7[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
      %9 = arith.maxnumf %8, %cst : vector<5x64xf32>
      %10 = vector.transfer_write %9, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = tensor.empty() : tensor<1x1x5x64xf32>
      %2 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %3 = vector.broadcast %2 : vector<64xf32> to vector<5x64xf32>
      %4 = vector.transfer_write %3, %1[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
      %5 = vector.transfer_read %4[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
      %6:2 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %4, %arg11 = %5) -> (tensor<1x1x5x64xf32>, vector<5x64xf32>) {
        %11:2 = scf.for %arg12 = %c0 to %c3 step %c1 iter_args(%arg13 = %arg10, %arg14 = %arg11) -> (tensor<1x1x5x64xf32>, vector<5x64xf32>) {
          %12:2 = scf.for %arg15 = %c0 to %c128 step %c1 iter_args(%arg16 = %arg13, %arg17 = %arg14) -> (tensor<1x1x5x64xf32>, vector<5x64xf32>) {
            %13 = vector.transfer_read %arg1[%arg15, %arg9, %arg12, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %14 = vector.broadcast %13 : vector<64xf32> to vector<5x64xf32>
            %15 = affine.apply #map()[%arg5, %arg9]
            %16 = affine.apply #map()[%arg6, %arg12]
            %17 = vector.transfer_read %arg0[%arg4, %15, %16, %arg15], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %18 = vector.broadcast %17 : vector<5xf32> to vector<64x5xf32>
            %19 = vector.transpose %18, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %20 = arith.mulf %14, %19 : vector<5x64xf32>
            %21 = arith.addf %arg17, %20 : vector<5x64xf32>
            scf.yield %arg16, %21 : tensor<1x1x5x64xf32>, vector<5x64xf32>
          }
          scf.yield %12#0, %12#1 : tensor<1x1x5x64xf32>, vector<5x64xf32>
        }
        scf.yield %11#0, %11#1 : tensor<1x1x5x64xf32>, vector<5x64xf32>
      }
      %7 = vector.transfer_write %6#1, %6#0[%c0, %c0, %c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<1x1x5x64xf32>
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %8 = vector.transfer_read %7[%c0, %c0, %c0, %c0], %cst_0 {in_bounds = [true, true]} : tensor<1x1x5x64xf32>, vector<5x64xf32>
      %9 = arith.maxnumf %8, %cst : vector<5x64xf32>
      %10 = vector.transfer_write %9, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %10 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %2 = vector.broadcast %1 : vector<64xf32> to vector<5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (vector<5x64xf32>) {
        %6 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (vector<5x64xf32>) {
          %7 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (vector<5x64xf32>) {
            %8 = vector.transfer_read %arg1[%arg13, %arg9, %arg11, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %9 = vector.broadcast %8 : vector<64xf32> to vector<5x64xf32>
            %10 = affine.apply #map()[%arg5, %arg9]
            %11 = affine.apply #map()[%arg6, %arg11]
            %12 = vector.transfer_read %arg0[%arg4, %10, %11, %arg13], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %13 = vector.broadcast %12 : vector<5xf32> to vector<64x5xf32>
            %14 = vector.transpose %13, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %15 = arith.mulf %9, %14 : vector<5x64xf32>
            %16 = arith.addf %arg14, %15 : vector<5x64xf32>
            scf.yield %16 : vector<5x64xf32>
          }
          scf.yield %7 : vector<5x64xf32>
        }
        scf.yield %6 : vector<5x64xf32>
      }
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %4 = arith.maxnumf %3, %cst : vector<5x64xf32>
      %5 = vector.transfer_write %4, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %5 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %2 = vector.broadcast %1 : vector<64xf32> to vector<5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (vector<5x64xf32>) {
        %6 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (vector<5x64xf32>) {
          %7 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (vector<5x64xf32>) {
            %8 = vector.transfer_read %arg1[%arg13, %arg9, %arg11, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %9 = vector.broadcast %8 : vector<64xf32> to vector<5x64xf32>
            %10 = affine.apply #map()[%arg5, %arg9]
            %11 = affine.apply #map()[%arg6, %arg11]
            %12 = vector.transfer_read %arg0[%arg4, %10, %11, %arg13], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %13 = vector.broadcast %12 : vector<5xf32> to vector<64x5xf32>
            %14 = vector.transpose %13, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %15 = arith.mulf %9, %14 : vector<5x64xf32>
            %16 = arith.addf %arg14, %15 : vector<5x64xf32>
            scf.yield %16 : vector<5x64xf32>
          }
          scf.yield %7 : vector<5x64xf32>
        }
        scf.yield %6 : vector<5x64xf32>
      }
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %4 = arith.maxnumf %3, %cst : vector<5x64xf32>
      %5 = vector.transfer_write %4, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %5 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump Before OneShotBufferize (one-shot-bufferize) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: tensor<5x82x102x128xf32>, %arg1: tensor<128x3x3x128xf32>, %arg2: tensor<128xf32>, %arg3: tensor<5x80x100x128xf32>) -> tensor<5x80x100x128xf32> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    %0 = scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) shared_outs(%arg8 = %arg3) -> (tensor<5x80x100x128xf32>) {
      %1 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : tensor<128xf32>, vector<64xf32>
      %2 = vector.broadcast %1 : vector<64xf32> to vector<5x64xf32>
      %3 = scf.for %arg9 = %c0 to %c3 step %c1 iter_args(%arg10 = %2) -> (vector<5x64xf32>) {
        %6 = scf.for %arg11 = %c0 to %c3 step %c1 iter_args(%arg12 = %arg10) -> (vector<5x64xf32>) {
          %7 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %arg12) -> (vector<5x64xf32>) {
            %8 = vector.transfer_read %arg1[%arg13, %arg9, %arg11, %arg7], %cst_0 {in_bounds = [true]} : tensor<128x3x3x128xf32>, vector<64xf32>
            %9 = vector.broadcast %8 : vector<64xf32> to vector<5x64xf32>
            %10 = affine.apply #map()[%arg5, %arg9]
            %11 = affine.apply #map()[%arg6, %arg11]
            %12 = vector.transfer_read %arg0[%arg4, %10, %11, %arg13], %cst_0 {in_bounds = [true], permutation_map = #map1} : tensor<5x82x102x128xf32>, vector<5xf32>
            %13 = vector.broadcast %12 : vector<5xf32> to vector<64x5xf32>
            %14 = vector.transpose %13, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %15 = arith.mulf %9, %14 : vector<5x64xf32>
            %16 = arith.addf %arg14, %15 : vector<5x64xf32>
            scf.yield %16 : vector<5x64xf32>
          }
          scf.yield %7 : vector<5x64xf32>
        }
        scf.yield %6 : vector<5x64xf32>
      }
      %extracted_slice = tensor.extract_slice %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x80x100x128xf32> to tensor<1x1x5x64xf32>
      %extracted_slice_1 = tensor.extract_slice %extracted_slice[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<1x1x5x64xf32> to tensor<5x64xf32>
      %4 = arith.maxnumf %3, %cst : vector<5x64xf32>
      %5 = vector.transfer_write %4, %extracted_slice_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, tensor<5x64xf32>
      scf.forall.in_parallel {
        tensor.parallel_insert_slice %5 into %arg8[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : tensor<5x64xf32> into tensor<5x80x100x128xf32>
      }
    }
    return %0 : tensor<5x80x100x128xf32>
  }
}


// -----// IR Dump After OneShotBufferize (one-shot-bufferize) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg1: memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg2: memref<128xf32, strided<[?], offset: ?>>, %arg3: memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>) -> memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) {
      %0 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : memref<128xf32, strided<[?], offset: ?>>, vector<64xf32>
      %1 = vector.broadcast %0 : vector<64xf32> to vector<5x64xf32>
      %2 = scf.for %arg8 = %c0 to %c3 step %c1 iter_args(%arg9 = %1) -> (vector<5x64xf32>) {
        %4 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %arg9) -> (vector<5x64xf32>) {
          %5 = scf.for %arg12 = %c0 to %c128 step %c1 iter_args(%arg13 = %arg11) -> (vector<5x64xf32>) {
            %6 = vector.transfer_read %arg1[%arg12, %arg8, %arg10, %arg7], %cst_0 {in_bounds = [true]} : memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<64xf32>
            %7 = vector.broadcast %6 : vector<64xf32> to vector<5x64xf32>
            %8 = affine.apply #map()[%arg5, %arg8]
            %9 = affine.apply #map()[%arg6, %arg10]
            %10 = vector.transfer_read %arg0[%arg4, %8, %9, %arg12], %cst_0 {in_bounds = [true], permutation_map = #map1} : memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<5xf32>
            %11 = vector.broadcast %10 : vector<5xf32> to vector<64x5xf32>
            %12 = vector.transpose %11, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %13 = arith.mulf %7, %12 : vector<5x64xf32>
            %14 = arith.addf %arg13, %13 : vector<5x64xf32>
            scf.yield %14 : vector<5x64xf32>
          }
          scf.yield %5 : vector<5x64xf32>
        }
        scf.yield %4 : vector<5x64xf32>
      }
      %subview = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>>
      %subview_1 = memref.subview %subview[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      %3 = arith.maxnumf %2, %cst : vector<5x64xf32>
      vector.transfer_write %3, %subview_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, memref<5x64xf32, strided<[?, ?], offset: ?>>
      %subview_2 = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      memref.copy %subview_1, %subview_2 : memref<5x64xf32, strided<[?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
    }
    return %arg3 : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>
  }
}


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg1: memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg2: memref<128xf32, strided<[?], offset: ?>>, %arg3: memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>) -> memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) {
      %0 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : memref<128xf32, strided<[?], offset: ?>>, vector<64xf32>
      %1 = vector.broadcast %0 : vector<64xf32> to vector<5x64xf32>
      %2 = scf.for %arg8 = %c0 to %c3 step %c1 iter_args(%arg9 = %1) -> (vector<5x64xf32>) {
        %4 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %arg9) -> (vector<5x64xf32>) {
          %5 = scf.for %arg12 = %c0 to %c128 step %c1 iter_args(%arg13 = %arg11) -> (vector<5x64xf32>) {
            %6 = vector.transfer_read %arg1[%arg12, %arg8, %arg10, %arg7], %cst_0 {in_bounds = [true]} : memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<64xf32>
            %7 = vector.broadcast %6 : vector<64xf32> to vector<5x64xf32>
            %8 = affine.apply #map()[%arg5, %arg8]
            %9 = affine.apply #map()[%arg6, %arg10]
            %10 = vector.transfer_read %arg0[%arg4, %8, %9, %arg12], %cst_0 {in_bounds = [true], permutation_map = #map1} : memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<5xf32>
            %11 = vector.broadcast %10 : vector<5xf32> to vector<64x5xf32>
            %12 = vector.transpose %11, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %13 = arith.mulf %7, %12 : vector<5x64xf32>
            %14 = arith.addf %arg13, %13 : vector<5x64xf32>
            scf.yield %14 : vector<5x64xf32>
          }
          scf.yield %5 : vector<5x64xf32>
        }
        scf.yield %4 : vector<5x64xf32>
      }
      %subview = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>>
      %subview_1 = memref.subview %subview[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      %3 = arith.maxnumf %2, %cst : vector<5x64xf32>
      vector.transfer_write %3, %subview_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, memref<5x64xf32, strided<[?, ?], offset: ?>>
      %subview_2 = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      memref.copy %subview_1, %subview_2 : memref<5x64xf32, strided<[?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
    }
    return %arg3 : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>
  }
}


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg1: memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg2: memref<128xf32, strided<[?], offset: ?>>, %arg3: memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>) -> memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) {
      %0 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : memref<128xf32, strided<[?], offset: ?>>, vector<64xf32>
      %1 = vector.broadcast %0 : vector<64xf32> to vector<5x64xf32>
      %2 = scf.for %arg8 = %c0 to %c3 step %c1 iter_args(%arg9 = %1) -> (vector<5x64xf32>) {
        %4 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %arg9) -> (vector<5x64xf32>) {
          %5 = scf.for %arg12 = %c0 to %c128 step %c1 iter_args(%arg13 = %arg11) -> (vector<5x64xf32>) {
            %6 = vector.transfer_read %arg1[%arg12, %arg8, %arg10, %arg7], %cst_0 {in_bounds = [true]} : memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<64xf32>
            %7 = vector.broadcast %6 : vector<64xf32> to vector<5x64xf32>
            %8 = affine.apply #map()[%arg5, %arg8]
            %9 = affine.apply #map()[%arg6, %arg10]
            %10 = vector.transfer_read %arg0[%arg4, %8, %9, %arg12], %cst_0 {in_bounds = [true], permutation_map = #map1} : memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<5xf32>
            %11 = vector.broadcast %10 : vector<5xf32> to vector<64x5xf32>
            %12 = vector.transpose %11, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %13 = arith.mulf %7, %12 : vector<5x64xf32>
            %14 = arith.addf %arg13, %13 : vector<5x64xf32>
            scf.yield %14 : vector<5x64xf32>
          }
          scf.yield %5 : vector<5x64xf32>
        }
        scf.yield %4 : vector<5x64xf32>
      }
      %subview = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>>
      %subview_1 = memref.subview %subview[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      %3 = arith.maxnumf %2, %cst : vector<5x64xf32>
      vector.transfer_write %3, %subview_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, memref<5x64xf32, strided<[?, ?], offset: ?>>
      %subview_2 = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      memref.copy %subview_1, %subview_2 : memref<5x64xf32, strided<[?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
    }
    return %arg3 : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>
  }
}


// -----// IR Dump Before FoldMemRefAliasOps (fold-memref-alias-ops) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg1: memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg2: memref<128xf32, strided<[?], offset: ?>>, %arg3: memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>) -> memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) {
      %0 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : memref<128xf32, strided<[?], offset: ?>>, vector<64xf32>
      %1 = vector.broadcast %0 : vector<64xf32> to vector<5x64xf32>
      %2 = scf.for %arg8 = %c0 to %c3 step %c1 iter_args(%arg9 = %1) -> (vector<5x64xf32>) {
        %4 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %arg9) -> (vector<5x64xf32>) {
          %5 = scf.for %arg12 = %c0 to %c128 step %c1 iter_args(%arg13 = %arg11) -> (vector<5x64xf32>) {
            %6 = vector.transfer_read %arg1[%arg12, %arg8, %arg10, %arg7], %cst_0 {in_bounds = [true]} : memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<64xf32>
            %7 = vector.broadcast %6 : vector<64xf32> to vector<5x64xf32>
            %8 = affine.apply #map()[%arg5, %arg8]
            %9 = affine.apply #map()[%arg6, %arg10]
            %10 = vector.transfer_read %arg0[%arg4, %8, %9, %arg12], %cst_0 {in_bounds = [true], permutation_map = #map1} : memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<5xf32>
            %11 = vector.broadcast %10 : vector<5xf32> to vector<64x5xf32>
            %12 = vector.transpose %11, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %13 = arith.mulf %7, %12 : vector<5x64xf32>
            %14 = arith.addf %arg13, %13 : vector<5x64xf32>
            scf.yield %14 : vector<5x64xf32>
          }
          scf.yield %5 : vector<5x64xf32>
        }
        scf.yield %4 : vector<5x64xf32>
      }
      %subview = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>>
      %subview_1 = memref.subview %subview[0, 0, 0, 0] [1, 1, 5, 64] [1, 1, 1, 1] : memref<1x1x5x64xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      %3 = arith.maxnumf %2, %cst : vector<5x64xf32>
      vector.transfer_write %3, %subview_1[%c0, %c0] {in_bounds = [true, true]} : vector<5x64xf32>, memref<5x64xf32, strided<[?, ?], offset: ?>>
      %subview_2 = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      memref.copy %subview_1, %subview_2 : memref<5x64xf32, strided<[?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
    }
    return %arg3 : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>
  }
}


// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) ('builtin.module' operation) //----- //
#map = affine_map<()[s0, s1] -> (s0 + s1)>
#map1 = affine_map<(d0, d1, d2, d3) -> (d2)>
module {
  func.func @conv(%arg0: memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg1: memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, %arg2: memref<128xf32, strided<[?], offset: ?>>, %arg3: memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>) -> memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> {
    %cst = arith.constant dense<0.000000e+00> : vector<5x64xf32>
    %c1 = arith.constant 1 : index
    %c128 = arith.constant 128 : index
    %c3 = arith.constant 3 : index
    %c0 = arith.constant 0 : index
    %cst_0 = arith.constant 0.000000e+00 : f32
    scf.forall (%arg4, %arg5, %arg6, %arg7) = (0, 0, 0, 0) to (5, 80, 100, 128) step (1, 1, 5, 64) {
      %0 = vector.transfer_read %arg2[%arg7], %cst_0 {in_bounds = [true]} : memref<128xf32, strided<[?], offset: ?>>, vector<64xf32>
      %1 = vector.broadcast %0 : vector<64xf32> to vector<5x64xf32>
      %2 = scf.for %arg8 = %c0 to %c3 step %c1 iter_args(%arg9 = %1) -> (vector<5x64xf32>) {
        %4 = scf.for %arg10 = %c0 to %c3 step %c1 iter_args(%arg11 = %arg9) -> (vector<5x64xf32>) {
          %5 = scf.for %arg12 = %c0 to %c128 step %c1 iter_args(%arg13 = %arg11) -> (vector<5x64xf32>) {
            %6 = vector.transfer_read %arg1[%arg12, %arg8, %arg10, %arg7], %cst_0 {in_bounds = [true]} : memref<128x3x3x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<64xf32>
            %7 = vector.broadcast %6 : vector<64xf32> to vector<5x64xf32>
            %8 = affine.apply #map()[%arg5, %arg8]
            %9 = affine.apply #map()[%arg6, %arg10]
            %10 = vector.transfer_read %arg0[%arg4, %8, %9, %arg12], %cst_0 {in_bounds = [true], permutation_map = #map1} : memref<5x82x102x128xf32, strided<[?, ?, ?, ?], offset: ?>>, vector<5xf32>
            %11 = vector.broadcast %10 : vector<5xf32> to vector<64x5xf32>
            %12 = vector.transpose %11, [1, 0] : vector<64x5xf32> to vector<5x64xf32>
            %13 = arith.mulf %7, %12 : vector<5x64xf32>
            %14 = arith.addf %arg13, %13 : vector<5x64xf32>
            scf.yield %14 : vector<5x64xf32>
          }
          scf.yield %5 : vector<5x64xf32>
        }
        scf.yield %4 : vector<5x64xf32>
      }
      %subview = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      %3 = arith.maxnumf %2, %cst : vector<5x64xf32>
      vector.transfer_write %3, %arg3[%arg4, %arg5, %arg6, %arg7] {in_bounds = [true, true]} : vector<5x64xf32>, memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>
      %subview_1 = memref.subview %arg3[%arg4, %arg5, %arg6, %arg7] [1, 1, 5, 64] [1, 1, 1, 1] : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
      memref.copy %subview, %subview_1 : memref<5x64xf32, strided<[?, ?], offset: ?>> to memref<5x64xf32, strided<[?, ?], offset: ?>>
    }
    return %arg3 : memref<5x80x100x128xf32, strided<[?, ?, ?, ?], offset: ?>>
  }
}


